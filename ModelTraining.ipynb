{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "# Check if GPU is available and use it if possible\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'Using device: {device}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define Paths\n",
    "training_path = \"C:\\\\Users\\\\Victus\\\\Desktop\\\\Oragan Clasifier\\\\training\"\n",
    "val_path = \"C:\\\\Users\\\\Victus\\\\Desktop\\\\Oragan Clasifier\\\\val\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Transforms for Data Augmentation and Normalization\n",
    "transform = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(20),\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "train_data = datasets.ImageFolder(root=training_path, transform=transform['train'])\n",
    "val_data = datasets.ImageFolder(root=val_path, transform=transform['val'])\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_data, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Labels: ['brain', 'hands', 'knee', 'lungs']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Verify Class Labels\n",
    "print(\"Class Labels:\", train_data.classes)  # Should output: ['brain', 'hands', 'knee', 'lungs']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Use Pre-trained Model (Transfer Learning) - ResNet18\n",
    "model = models.resnet18(pretrained=True)\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, len(train_data.classes))  # Modify the output layer to 4 classes\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define Loss and Optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the Model\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=50):\n",
    "    best_accuracy = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()  # Set the model to training mode\n",
    "        running_loss = 0.0\n",
    "\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            # Forward Pass\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Backward Pass and Optimization\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {running_loss / len(train_loader):.4f}')\n",
    "\n",
    "        # Evaluate on Validation Set\n",
    "        val_accuracy = evaluate_model(model, val_loader)\n",
    "\n",
    "        # Save the model if it achieves the best accuracy\n",
    "        if val_accuracy > best_accuracy:\n",
    "            best_accuracy = val_accuracy\n",
    "            torch.save(model.state_dict(), 'organ_classifier.pth')\n",
    "            print(\"Model saved!\")\n",
    "\n",
    "    print(f'Best Validation Accuracy: {best_accuracy:.4f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Loss: 0.5407\n",
      "Validation Accuracy: 22.03%\n",
      "Model saved!\n",
      "Epoch [2/50], Loss: 0.3296\n",
      "Validation Accuracy: 84.75%\n",
      "Model saved!\n",
      "Epoch [3/50], Loss: 0.2992\n",
      "Validation Accuracy: 20.34%\n",
      "Epoch [4/50], Loss: 0.2715\n",
      "Validation Accuracy: 38.98%\n",
      "Epoch [5/50], Loss: 0.1876\n",
      "Validation Accuracy: 81.36%\n",
      "Epoch [6/50], Loss: 0.0930\n",
      "Validation Accuracy: 94.92%\n",
      "Model saved!\n",
      "Epoch [7/50], Loss: 0.3158\n",
      "Validation Accuracy: 89.83%\n",
      "Epoch [8/50], Loss: 0.2159\n",
      "Validation Accuracy: 64.41%\n",
      "Epoch [9/50], Loss: 0.1763\n",
      "Validation Accuracy: 69.49%\n",
      "Epoch [10/50], Loss: 0.0986\n",
      "Validation Accuracy: 91.53%\n",
      "Epoch [11/50], Loss: 0.2016\n",
      "Validation Accuracy: 89.83%\n",
      "Epoch [12/50], Loss: 0.1107\n",
      "Validation Accuracy: 96.61%\n",
      "Model saved!\n",
      "Epoch [13/50], Loss: 0.0612\n",
      "Validation Accuracy: 93.22%\n",
      "Epoch [14/50], Loss: 0.0769\n",
      "Validation Accuracy: 98.31%\n",
      "Model saved!\n",
      "Epoch [15/50], Loss: 0.1128\n",
      "Validation Accuracy: 89.83%\n",
      "Epoch [16/50], Loss: 0.0714\n",
      "Validation Accuracy: 84.75%\n",
      "Epoch [17/50], Loss: 0.0859\n",
      "Validation Accuracy: 96.61%\n",
      "Epoch [18/50], Loss: 0.0674\n",
      "Validation Accuracy: 98.31%\n",
      "Epoch [19/50], Loss: 0.0407\n",
      "Validation Accuracy: 98.31%\n",
      "Epoch [20/50], Loss: 0.0423\n",
      "Validation Accuracy: 98.31%\n",
      "Epoch [21/50], Loss: 0.0436\n",
      "Validation Accuracy: 96.61%\n",
      "Epoch [22/50], Loss: 0.0319\n",
      "Validation Accuracy: 98.31%\n",
      "Epoch [23/50], Loss: 0.0582\n",
      "Validation Accuracy: 96.61%\n",
      "Epoch [24/50], Loss: 0.0852\n",
      "Validation Accuracy: 89.83%\n",
      "Epoch [25/50], Loss: 0.0767\n",
      "Validation Accuracy: 91.53%\n",
      "Epoch [26/50], Loss: 0.1041\n",
      "Validation Accuracy: 91.53%\n",
      "Epoch [27/50], Loss: 0.0701\n",
      "Validation Accuracy: 83.05%\n",
      "Epoch [28/50], Loss: 0.3504\n",
      "Validation Accuracy: 86.44%\n",
      "Epoch [29/50], Loss: 0.0348\n",
      "Validation Accuracy: 74.58%\n",
      "Epoch [30/50], Loss: 0.0483\n",
      "Validation Accuracy: 71.19%\n",
      "Epoch [31/50], Loss: 0.1687\n",
      "Validation Accuracy: 96.61%\n",
      "Epoch [32/50], Loss: 0.1399\n",
      "Validation Accuracy: 88.14%\n",
      "Epoch [33/50], Loss: 0.1204\n",
      "Validation Accuracy: 96.61%\n",
      "Epoch [34/50], Loss: 0.1183\n",
      "Validation Accuracy: 94.92%\n",
      "Epoch [35/50], Loss: 0.1649\n",
      "Validation Accuracy: 86.44%\n",
      "Epoch [36/50], Loss: 0.0516\n",
      "Validation Accuracy: 88.14%\n",
      "Epoch [37/50], Loss: 0.0614\n",
      "Validation Accuracy: 89.83%\n",
      "Epoch [38/50], Loss: 0.1743\n",
      "Validation Accuracy: 93.22%\n",
      "Epoch [39/50], Loss: 0.1785\n",
      "Validation Accuracy: 25.42%\n",
      "Epoch [40/50], Loss: 0.1318\n",
      "Validation Accuracy: 50.85%\n",
      "Epoch [41/50], Loss: 0.0952\n",
      "Validation Accuracy: 74.58%\n",
      "Epoch [42/50], Loss: 0.1786\n",
      "Validation Accuracy: 86.44%\n",
      "Epoch [43/50], Loss: 0.1184\n",
      "Validation Accuracy: 84.75%\n",
      "Epoch [44/50], Loss: 0.1364\n",
      "Validation Accuracy: 88.14%\n",
      "Epoch [45/50], Loss: 0.0835\n",
      "Validation Accuracy: 86.44%\n",
      "Epoch [46/50], Loss: 0.0529\n",
      "Validation Accuracy: 84.75%\n",
      "Epoch [47/50], Loss: 0.0549\n",
      "Validation Accuracy: 89.83%\n",
      "Epoch [48/50], Loss: 0.0942\n",
      "Validation Accuracy: 94.92%\n",
      "Epoch [49/50], Loss: 0.0574\n",
      "Validation Accuracy: 91.53%\n",
      "Epoch [50/50], Loss: 0.1065\n",
      "Validation Accuracy: 89.83%\n",
      "Best Validation Accuracy: 98.3051%\n"
     ]
    }
   ],
   "source": [
    "def evaluate_model(model, loader):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f'Validation Accuracy: {accuracy:.2f}%')\n",
    "    return accuracy\n",
    "\n",
    "# Train the Model\n",
    "train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=50)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
